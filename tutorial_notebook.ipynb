{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00999664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os \n",
    "current_dir = os.getcwd()\n",
    "path = os.path.dirname(current_dir)\n",
    "sys.path.append(path)\n",
    "\n",
    "from ml_workflow.tuned_estimator import TunedEstimator\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import average_precision_score \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b56ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_classification(n_samples=10000, random_state=42, class_sep=0.7)\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdf68c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the estimator that will be using.\n",
    "# Can be any scikit-learn model or scikit-learn-style model (XGBoost). \n",
    "estimator = RandomForestClassifier(n_jobs=-1, random_state=30, criterion = 'entropy',) \n",
    "\n",
    "# Define the ML pipeline. \n",
    "# A pipeline is a wrapper around the ML model itself,\n",
    "# that performs as pre-processing procedures. \n",
    "# These methods are saved as attributes of the \n",
    "# Pipeline class and saved directly with it. \n",
    "\n",
    "# if pipeline_kwargs = None, then no pipeline is created\n",
    "# and what's returned is the ML model by itself. \n",
    "\n",
    "pipeline_kwargs = dict(\n",
    "    # Method to handle missing data.\n",
    "    imputer = 'simple', # None, 'simple', 'iterative'\n",
    "    # Whether to scale the input data and the method\n",
    "    scaler = 'standard', # None, 'minmax', 'standard', 'robust'\n",
    "    # Whether to perform Principal component transform\n",
    "    pca = None, # True, None/False\n",
    "    # Whether to resample the dataset to artifically\n",
    "    # increase the base rate; useful for highly imbalanced dataset\n",
    "    # CAUTION: resampling requires calibration afterwards! \n",
    "    \n",
    "    # Specify which features are numerical or categorical.\n",
    "    # For categorical features, we do not want to apply \n",
    "    # certain scaling methods. Default is None \n",
    "    # and all features treated as numerical.\n",
    "    numeric_features = None, \n",
    "    categorical_features= None\n",
    ")\n",
    "\n",
    "# Define the hyperparameter optimizer \n",
    "\n",
    "def scorer(estimator, X, y):\n",
    "    pred = estimator.predict_proba(X)[:,1]\n",
    "    return 1.0 - average_precision_score(y, pred)\n",
    "\n",
    "hyperopt_kwargs = dict(\n",
    "    # Create a hyperparameter search grid. \n",
    "    search_space = {  'n_estimators' : [100,150,300,400,500], \n",
    "                      'max_depth' : [6,8,10,15,20],\n",
    "                      'max_features' : [5,6,8,10],\n",
    "                      'min_samples_split' : [4,5,8,10,15,20,25,50],\n",
    "                      'min_samples_leaf' : [4,5,8,10,15,20,25,50],\n",
    "             },\n",
    "    # Optimizer method, leave it as \"tpe\"\n",
    "    optimizer = \"tpe\", \n",
    "    # Number of settings to explore. \n",
    "    max_evals = 5,\n",
    "    # Number of steps before exiting if a 1%\n",
    "    # improvement in the score does not occur.\n",
    "    patience = 10,\n",
    "    # Method that returns a single score and takes\n",
    "    # callable of form scorer(estimator, X, y)\n",
    "    scorer = scorer, \n",
    "    # Jobs to run in parallel, \n",
    "    # CAUTION: set == 1, if the estimator is \n",
    "    # already run in parallel (e.g., a random forest),\n",
    "    # as it cause conflicts\n",
    "    n_jobs=1,\n",
    "    # the CV method to use\n",
    "    cv = None, \n",
    "    \n",
    "    # Output filename of the hyperparam results.\n",
    "    # Results can be viewed later. \n",
    "    output_fname = None\n",
    "   \n",
    ")\n",
    "\n",
    "# Define calibration method \n",
    "# NOTE: Only define if performing classification; \n",
    "# no method exists for regression calibration at the moment. \n",
    "calibration_cv_kwargs = None\n",
    "\n",
    "\n",
    "tuned_estimator = TunedEstimator(estimator, \n",
    "                                 pipeline_kwargs,\n",
    "                                 hyperopt_kwargs,\n",
    "                                 calibration_cv_kwargs,\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f6a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_estimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ddbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('hyperopt_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63155a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
